import OpenAI from "openai";
import { splitIntoSentences, splitIntoChunks } from "./textExtractor";
import type { HighlightedSection } from "@shared/schema";

const openai = new OpenAI({
  apiKey: process.env.AI_INTEGRATIONS_OPENAI_API_KEY,
  baseURL: process.env.AI_INTEGRATIONS_OPENAI_BASE_URL,
});

interface ScanResult {
  overallScore: number;
  aiScore: number;
  webScore: number;
  verdict: "original" | "low" | "moderate" | "high";
  highlightedSections: HighlightedSection[];
  sourceMatches: {
    sourceUrl: string | null;
    sourceTitle: string | null;
    matchedText: string;
    originalText: string;
    similarityScore: number;
    startIndex: number;
    endIndex: number;
    matchType: "ai" | "web" | "paraphrase";
  }[];
}

function getMatchLevel(score: number): "high" | "medium" | "low" {
  if (score >= 80) return "high";
  if (score >= 50) return "medium";
  return "low";
}

function getVerdict(score: number): "original" | "low" | "moderate" | "high" {
  if (score < 15) return "original";
  if (score < 30) return "low";
  if (score < 50) return "moderate";
  return "high";
}

async function detectAIContent(text: string): Promise<{
  score: number;
  sections: { text: string; score: number; startIndex: number; endIndex: number }[];
}> {
  const chunks = splitIntoChunks(text, 500);
  const results: { text: string; score: number; startIndex: number; endIndex: number }[] = [];
  let totalScore = 0;
  let currentIndex = 0;

  for (const chunk of chunks.slice(0, 8)) {
    try {
      const response = await openai.chat.completions.create({
        model: "gpt-4o",
        messages: [
          {
            role: "system",
            content: `You are an expert AI content detector with deep knowledge of how AI language models generate text. Analyze the following text carefully and estimate the probability (0-100) that it was generated by an AI like ChatGPT, Claude, or similar models.

DETECTION CRITERIA - Look for these AI-generated content indicators:
1. STRUCTURAL PATTERNS:
   - Unnaturally perfect grammar and punctuation
   - Consistent paragraph lengths
   - Formulaic transitions ("Furthermore," "Moreover," "In conclusion")
   - Lists and bullet points in prose
   
2. LINGUISTIC MARKERS:
   - Hedging language ("It's important to note," "It should be mentioned")
   - Overly balanced arguments without strong opinions
   - Generic, non-specific examples
   - Repetitive sentence structures
   
3. CONTENT CHARACTERISTICS:
   - Lack of personal anecdotes or unique experiences
   - Absence of typos, colloquialisms, or informal language
   - Encyclopedic tone rather than conversational
   - Excessive use of transitional phrases

4. SEMANTIC PATTERNS:
   - Broad coverage without deep expertise
   - Predictable topic progression
   - Lack of controversial or bold claims
   - Generic conclusions that summarize rather than conclude with new insights

SCORING GUIDELINES:
- 0-20: Clearly human-written (personal voice, unique style, natural imperfections)
- 21-40: Likely human-written (minor AI-like patterns, possibly edited)
- 41-60: Uncertain (mixed signals, could be AI-assisted)
- 61-80: Likely AI-generated (multiple AI markers present)
- 81-100: Clearly AI-generated (strong AI patterns throughout)

Be accurate and avoid false positives. Academic or formal writing isn't automatically AI-generated.

Respond with ONLY a valid JSON object: {"score": number, "reason": "specific explanation citing observed patterns"}`
          },
          {
            role: "user",
            content: chunk
          }
        ],
        max_completion_tokens: 250,
      });

      const content = response.choices[0]?.message?.content || '{"score": 0}';
      const cleanedContent = content.replace(/```json\n?|\n?```/g, "").trim();
      const parsed = JSON.parse(cleanedContent);
      const score = Math.min(100, Math.max(0, parsed.score || 0));

      const startIndex = text.indexOf(chunk);
      results.push({
        text: chunk,
        score,
        startIndex: startIndex >= 0 ? startIndex : currentIndex,
        endIndex: (startIndex >= 0 ? startIndex : currentIndex) + chunk.length,
      });
      totalScore += score;
    } catch (error) {
      console.error("AI detection error for chunk:", error);
    }
    currentIndex += chunk.length + 1;
  }

  return {
    score: results.length > 0 ? totalScore / results.length : 0,
    sections: results.filter(r => r.score > 35),
  };
}

async function checkWebPlagiarism(text: string): Promise<{
  score: number;
  matches: {
    sourceUrl: string | null;
    sourceTitle: string | null;
    matchedText: string;
    originalText: string;
    similarityScore: number;
    startIndex: number;
    endIndex: number;
  }[];
}> {
  const sentences = splitIntoSentences(text);
  const sampleSentences = sentences.slice(0, 15);
  const matches: {
    sourceUrl: string | null;
    sourceTitle: string | null;
    matchedText: string;
    originalText: string;
    similarityScore: number;
    startIndex: number;
    endIndex: number;
  }[] = [];

  try {
    const response = await openai.chat.completions.create({
      model: "gpt-4o",
      messages: [
        {
          role: "system",
          content: `You are an expert plagiarism detection assistant with extensive knowledge of common academic and online content. Analyze each sentence for potential plagiarism.

DETECTION CRITERIA:
1. EXACT MATCHES: Sentences that are verbatim copies from known sources
2. PARAPHRASED CONTENT: Text that closely mirrors known content with minor word changes
3. COMMON KNOWLEDGE: Widely known facts that don't require citation
4. UNIQUE CONTENT: Original writing with personal voice

ANALYSIS APPROACH:
- Check if the sentence structure/phrasing matches known patterns from textbooks, Wikipedia, academic papers
- Identify distinctive phrases that commonly appear in online sources
- Consider if the content is too polished or formulaic for student writing
- Look for technical definitions that are commonly copied verbatim

SCORING GUIDELINES:
- 0-30: Original content or common knowledge (no citation needed)
- 31-50: Possibly inspired by sources but adequately paraphrased
- 51-70: Likely paraphrased from sources without proper citation
- 71-90: Strongly resembles known content, probable plagiarism
- 91-100: Near-verbatim match to known sources

For each sentence, respond with a JSON object:
{
  "sentences": [
    {
      "original": "the exact sentence analyzed",
      "likelyCopied": boolean,
      "confidence": number (0-100),
      "potentialSource": "specific source type (e.g., 'Wikipedia article on X', 'Common textbook definition', 'Academic paper pattern') or null",
      "reason": "specific explanation of why this appears copied or original"
    }
  ]
}

Be thorough but accurate. Avoid false positives for common phrases that naturally occur in writing.`
        },
        {
          role: "user",
          content: `Analyze these sentences for potential plagiarism:\n\n${sampleSentences.map((s, i) => `${i + 1}. "${s}"`).join("\n")}`
        }
      ],
      max_completion_tokens: 1500,
    });

    const content = response.choices[0]?.message?.content || '{"sentences": []}';
    const cleanedContent = content.replace(/```json\n?|\n?```/g, "").trim();
    const parsed = JSON.parse(cleanedContent);
    
    for (const item of parsed.sentences || []) {
      if (item.likelyCopied && item.confidence > 45) {
        const startIndex = text.indexOf(item.original);
        if (startIndex >= 0) {
          matches.push({
            sourceUrl: null,
            sourceTitle: item.potentialSource || "Potential external source",
            matchedText: item.original,
            originalText: item.original,
            similarityScore: item.confidence,
            startIndex,
            endIndex: startIndex + item.original.length,
          });
        }
      }
    }
  } catch (error) {
    console.error("Web plagiarism check error:", error);
  }

  const avgScore = matches.length > 0
    ? matches.reduce((sum, m) => sum + m.similarityScore, 0) / matches.length
    : 0;

  return {
    score: Math.min(100, avgScore * (matches.length / Math.max(1, sampleSentences.length))),
    matches,
  };
}

export async function scanDocument(text: string): Promise<ScanResult> {
  const startTime = Date.now();

  const [aiResult, webResult] = await Promise.all([
    detectAIContent(text),
    checkWebPlagiarism(text),
  ]);

  const overallScore = Math.min(100, (aiResult.score * 0.6 + webResult.score * 0.4));
  const verdict = getVerdict(overallScore);

  const highlightedSections: HighlightedSection[] = [];
  const sourceMatches: ScanResult["sourceMatches"] = [];

  for (const section of aiResult.sections) {
    highlightedSections.push({
      text: section.text,
      startIndex: section.startIndex,
      endIndex: section.endIndex,
      similarityScore: section.score,
      matchType: getMatchLevel(section.score),
    });

    sourceMatches.push({
      sourceUrl: null,
      sourceTitle: "AI-Generated Content",
      matchedText: section.text.substring(0, 200) + (section.text.length > 200 ? "..." : ""),
      originalText: section.text.substring(0, 200) + (section.text.length > 200 ? "..." : ""),
      similarityScore: section.score,
      startIndex: section.startIndex,
      endIndex: section.endIndex,
      matchType: "ai",
    });
  }

  for (const match of webResult.matches) {
    highlightedSections.push({
      text: match.originalText,
      startIndex: match.startIndex,
      endIndex: match.endIndex,
      similarityScore: match.similarityScore,
      matchType: getMatchLevel(match.similarityScore),
    });

    sourceMatches.push({
      ...match,
      matchType: "web",
    });
  }

  return {
    overallScore,
    aiScore: aiResult.score,
    webScore: webResult.score,
    verdict,
    highlightedSections,
    sourceMatches,
  };
}
