import OpenAI from "openai";
import { splitIntoSentences, splitIntoChunks } from "./textExtractor";
import type { HighlightedSection } from "@shared/schema";

const openai = new OpenAI({
  apiKey: process.env.AI_INTEGRATIONS_OPENAI_API_KEY,
  baseURL: process.env.AI_INTEGRATIONS_OPENAI_BASE_URL,
});

interface ScanResult {
  overallScore: number;
  aiScore: number;
  webScore: number;
  verdict: "original" | "low" | "moderate" | "high";
  highlightedSections: HighlightedSection[];
  sourceMatches: {
    sourceUrl: string | null;
    sourceTitle: string | null;
    matchedText: string;
    originalText: string;
    similarityScore: number;
    startIndex: number;
    endIndex: number;
    matchType: "ai" | "web" | "paraphrase";
  }[];
}

function getMatchLevel(score: number): "high" | "medium" | "low" {
  if (score >= 80) return "high";
  if (score >= 50) return "medium";
  return "low";
}

function getVerdict(score: number): "original" | "low" | "moderate" | "high" {
  if (score < 15) return "original";
  if (score < 30) return "low";
  if (score < 50) return "moderate";
  return "high";
}

async function detectAIContent(text: string): Promise<{
  score: number;
  sections: { text: string; score: number; startIndex: number; endIndex: number }[];
}> {
  const chunks = splitIntoChunks(text, 300);
  const results: { text: string; score: number; startIndex: number; endIndex: number }[] = [];
  let totalScore = 0;
  let currentIndex = 0;

  for (const chunk of chunks.slice(0, 5)) {
    try {
      const response = await openai.chat.completions.create({
        model: "gpt-4o",
        messages: [
          {
            role: "system",
            content: `You are an AI content detector. Analyze the following text and estimate the probability (0-100) that it was generated by an AI like ChatGPT. Consider:
- Unusual perfection in grammar and structure
- Generic or templated phrasing
- Lack of personal voice or unique perspectives
- Overly balanced arguments
- Predictable transitions

Respond with ONLY a JSON object: {"score": number, "reason": "brief explanation"}`
          },
          {
            role: "user",
            content: chunk
          }
        ],
        temperature: 0.1,
        max_completion_tokens: 150,
      });

      const content = response.choices[0]?.message?.content || '{"score": 0}';
      const parsed = JSON.parse(content.replace(/```json\n?|\n?```/g, ""));
      const score = Math.min(100, Math.max(0, parsed.score || 0));

      const startIndex = text.indexOf(chunk);
      results.push({
        text: chunk,
        score,
        startIndex: startIndex >= 0 ? startIndex : currentIndex,
        endIndex: (startIndex >= 0 ? startIndex : currentIndex) + chunk.length,
      });
      totalScore += score;
    } catch (error) {
      console.error("AI detection error for chunk:", error);
    }
    currentIndex += chunk.length + 1;
  }

  return {
    score: results.length > 0 ? totalScore / results.length : 0,
    sections: results.filter(r => r.score > 40),
  };
}

async function checkWebPlagiarism(text: string): Promise<{
  score: number;
  matches: {
    sourceUrl: string | null;
    sourceTitle: string | null;
    matchedText: string;
    originalText: string;
    similarityScore: number;
    startIndex: number;
    endIndex: number;
  }[];
}> {
  const sentences = splitIntoSentences(text);
  const sampleSentences = sentences.slice(0, 10);
  const matches: {
    sourceUrl: string | null;
    sourceTitle: string | null;
    matchedText: string;
    originalText: string;
    similarityScore: number;
    startIndex: number;
    endIndex: number;
  }[] = [];

  try {
    const response = await openai.chat.completions.create({
      model: "gpt-4o",
      messages: [
        {
          role: "system",
          content: `You are a plagiarism detection assistant. For each sentence provided, assess if it appears to be commonly found or potentially copied content. 
          
Consider:
- Common phrases that might appear in multiple sources
- Academic or technical terminology that's often reused
- Direct quotes or well-known passages
- Generic content vs unique writing

For each sentence, respond with a JSON array of objects with this structure:
{
  "sentences": [
    {
      "original": "the original sentence",
      "likelyCopied": boolean,
      "confidence": number (0-100),
      "potentialSource": "description of likely source type or null",
      "reason": "brief explanation"
    }
  ]
}`
        },
        {
          role: "user",
          content: `Analyze these sentences for potential plagiarism:\n\n${sampleSentences.map((s, i) => `${i + 1}. "${s}"`).join("\n")}`
        }
      ],
      temperature: 0.1,
      max_completion_tokens: 1000,
    });

    const content = response.choices[0]?.message?.content || '{"sentences": []}';
    const parsed = JSON.parse(content.replace(/```json\n?|\n?```/g, ""));
    
    for (const item of parsed.sentences || []) {
      if (item.likelyCopied && item.confidence > 50) {
        const startIndex = text.indexOf(item.original);
        if (startIndex >= 0) {
          matches.push({
            sourceUrl: null,
            sourceTitle: item.potentialSource || "Unknown source",
            matchedText: item.original,
            originalText: item.original,
            similarityScore: item.confidence,
            startIndex,
            endIndex: startIndex + item.original.length,
          });
        }
      }
    }
  } catch (error) {
    console.error("Web plagiarism check error:", error);
  }

  const avgScore = matches.length > 0
    ? matches.reduce((sum, m) => sum + m.similarityScore, 0) / matches.length
    : 0;

  return {
    score: Math.min(100, avgScore * (matches.length / Math.max(1, sampleSentences.length))),
    matches,
  };
}

export async function scanDocument(text: string): Promise<ScanResult> {
  const startTime = Date.now();

  const [aiResult, webResult] = await Promise.all([
    detectAIContent(text),
    checkWebPlagiarism(text),
  ]);

  const overallScore = Math.min(100, (aiResult.score * 0.6 + webResult.score * 0.4));
  const verdict = getVerdict(overallScore);

  const highlightedSections: HighlightedSection[] = [];
  const sourceMatches: ScanResult["sourceMatches"] = [];

  for (const section of aiResult.sections) {
    highlightedSections.push({
      text: section.text,
      startIndex: section.startIndex,
      endIndex: section.endIndex,
      similarityScore: section.score,
      matchType: getMatchLevel(section.score),
    });

    sourceMatches.push({
      sourceUrl: null,
      sourceTitle: "AI-Generated Content",
      matchedText: section.text.substring(0, 200) + (section.text.length > 200 ? "..." : ""),
      originalText: section.text.substring(0, 200) + (section.text.length > 200 ? "..." : ""),
      similarityScore: section.score,
      startIndex: section.startIndex,
      endIndex: section.endIndex,
      matchType: "ai",
    });
  }

  for (const match of webResult.matches) {
    highlightedSections.push({
      text: match.originalText,
      startIndex: match.startIndex,
      endIndex: match.endIndex,
      similarityScore: match.similarityScore,
      matchType: getMatchLevel(match.similarityScore),
    });

    sourceMatches.push({
      ...match,
      matchType: "web",
    });
  }

  return {
    overallScore,
    aiScore: aiResult.score,
    webScore: webResult.score,
    verdict,
    highlightedSections,
    sourceMatches,
  };
}
